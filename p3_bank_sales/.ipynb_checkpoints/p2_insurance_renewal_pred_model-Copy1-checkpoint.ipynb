{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Stroke Risk Prediction #\n",
    "This is a capstone project for Springboard's data science intensive track. The dataset used in this project is sourced from the data science competition sponsor by McKinsey analytics and held in a platform \"Analytics Vidhya\". \n",
    "The competition link can be found here [contest page] (https://datahack.analyticsvidhya.com/contest/mckinsey-analytics-online-hackathon/).\n",
    "\n",
    "**Dataset:**\n",
    "The data source was contributed by a chain of hospital clients based in US for McKinsey consulting firm. McKinsey hosted this dataset as open data science hack competition on Analytics Vidhya. The dataset consists of N features on anonymized patients including mixed variables (i.e., numerical and categorical) such as patient ID, gender, health conditions and other demographic features. The volume of dataset contains about N patient cases.\n",
    "\n",
    "**Goal:** \n",
    "To develop a classification model predicts patients at high risks of developing a stroke condition\n",
    "\n",
    "**Results:**\n",
    "X% of auc_roc score made on test set of patient population using Logistic Regression classifier.\n",
    "\n",
    "**Risks:**\n",
    "Model incorrectly identified with X% of error (especially error being Type I error).\n",
    "\n",
    "**Mitigation:**\n",
    "Review identified cases with a group of clinicians before any clinical decision making\n",
    "\n",
    "**Next Steps for Future Work:**\n",
    "* Collection of meaningful features.\n",
    "* Model improvement: algorithms, resampling strategies and classifier designs (i.e., age-specific)\n",
    "\n",
    "**Recommendations for Clients:**\n",
    "1. Implement additional test\n",
    "2. Collect meaningful features for building an accurate model: \n",
    "3. Conduct cohort studies: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - DEFINE ##\n",
    "\n",
    "**Problem Statement:**  \n",
    "\n",
    "**Stakeholders:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import operator\n",
    "from itertools import cycle\n",
    "import scipy.stats as sp\n",
    "from scipy import interp\n",
    "from sklearn.externals import six\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.base as skb\n",
    "from sklearn.utils import shuffle, resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, RandomizedSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Authorship:\n",
    "__author__ = 'Taesun Yoo'\n",
    "__email__ = 'yoots1988@gmail.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVERY ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Write Out List of Functions --- #\n",
    "def load_file(file):\n",
    "    '''load the CSV files as a dataframe'''\n",
    "    df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "def drop_column_by_index(df, var):\n",
    "    '''drop a column by specified variable'''\n",
    "    df = df.drop(var, axis=1)\n",
    "    return df\n",
    "\n",
    "def join_data(df_train, df_label, key, \n",
    "              left_index=None, right_index=None):\n",
    "    '''Merge the feature and label dataframe(s)'''\n",
    "    df_join = pd.merge(df_train, df_label, how='inner', on=key,\n",
    "                         left_index=False, right_index=False)\n",
    "    return df_join\n",
    "\n",
    "def clean_data(df):\n",
    "    '''drop any duplicate based on specific column'''\n",
    "    clean_df = df.drop_duplicates(subset='id')\n",
    "    return clean_df\n",
    "\n",
    "def eda_missing_data(df):\n",
    "    missing_df = pd.DataFrame(df.isnull().sum())\n",
    "    missing_df.columns = ['count']\n",
    "    missing_df['pct'] = (missing_df['count']/len(df))*100\n",
    "    return missing_df\n",
    "\n",
    "def eda_summary_stat_num(df):\n",
    "    '''compute summary statistics for numerical variables'''\n",
    "    df_stat_num = df.describe().T\n",
    "    df_stat_num = df_stat_num[['count', 'min', 'mean', 'max', '25%', '50%', '75%', 'std']]\n",
    "    df_stat_num = df_stat_num.sort_values(by='count', ascending=True)\n",
    "    df_stat_num = pd.DataFrame(df_stat_num)\n",
    "    return df_stat_num\n",
    "\n",
    "def eda_summary_stat_cat(df):\n",
    "    '''compute summary statistics for categorical variables'''\n",
    "    df_stat_cat = pd.DataFrame(df.describe(include='O').T)\n",
    "    return df_stat_cat\n",
    "\n",
    "def compute_outliers(df_stat_num):\n",
    "    df_stat_num['IQR'] = df_stat_num['75%'] - df_stat_num['25%']\n",
    "    df_stat_num['UB'] = df_stat_num['75%'] + 1.5*df_stat_num['IQR']\n",
    "    df_stat_num['LB'] = df_stat_num['25%'] - 1.5*df_stat_num['IQR']\n",
    "    df_outliers = df_stat_num[['LB', 'min', 'UB', 'max']]\n",
    "    return df_outliers\n",
    "\n",
    "def EDA_plot_correlation(df_EDA):\n",
    "    '''compute and plot correlation matrix'''\n",
    "    corr = df_EDA.corr()\n",
    "    # Create a mask to filter matrix: diagonally\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    # Matrix Plot:\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "    sns.set(font_scale=1.1)\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "                annot=True, square=True, linewidths=.5, fmt=\".2f\",\n",
    "                annot_kws={'size':10}, cbar_kws={'shrink':.6})\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "def encode_categorical_feature(df, var_name, map_name):\n",
    "    '''encode categorical features into mapping values'''\n",
    "    df[var_name] = df[var_name].map(map_name)\n",
    "    return df[var_name]\n",
    "\n",
    "def feature_imputer(X, missing_val_format, method, indices):\n",
    "    '''imputes missing values based on different uni-variate methods'''\n",
    "    imputer = Imputer(missing_values=missing_val_format, strategy=method, axis=0)\n",
    "    imputer = imputer.fit(X.iloc[:, indices])\n",
    "    X.iloc[:, indices] = imputer.transform(X.iloc[:, indices])\n",
    "    return X.iloc[:, indices]\n",
    "\n",
    "def convert_data_type(df, var_name, dt_type):\n",
    "    '''convert data type into specified metadata type'''\n",
    "    df[var_name] = df[var_name].astype(dt_type)\n",
    "    return df[var_name]\n",
    "\n",
    "def split_dataframe(df):\n",
    "    '''Split dataframe into features and label'''\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "    return X, y\n",
    "\n",
    "def avg_groupby_data(df, num_var, cat_var, avg_var_name):\n",
    "    '''perform average group by categorical variable to compute a mean'''\n",
    "    avg_groupby_val = df.groupby(cat_var)[num_var].mean().sort_values(ascending=False)\n",
    "    avg_groupby_df = pd.DataFrame({cat_var:list(df[cat_var].unique()),\n",
    "                                   avg_var_name:avg_groupby_val})\n",
    "    avg_groupby_df.reset_index(drop=True, inplace=True)\n",
    "    return avg_groupby_df\n",
    "\n",
    "def left_join_data(train_df, avg_groupby_df, key=None, left_index=False, right_index=False):\n",
    "    '''performs left join on train data to average groupby data'''\n",
    "    joined_df = pd.merge(train_df, avg_groupby_df, how='left', on=key,\n",
    "                         left_index=left_index, right_index=right_index)\n",
    "    return joined_df\n",
    "\n",
    "def one_hot_encode_feature(df, cat_vars=None, num_vars=None):\n",
    "    '''performs one-hot encoding on all categorical variables and\n",
    "       combine results with numerical variables '''\n",
    "    cat_df = pd.get_dummies(df[cat_vars], drop_first=True)\n",
    "    num_df = df[num_vars].apply(pd.to_numeric)\n",
    "    return pd.concat([cat_df, num_df], axis=1)\n",
    "\n",
    "def get_label_data(df, label_var):\n",
    "    '''separate label from a dataframe'''\n",
    "    df_label = df[label_var]\n",
    "    return df_label\n",
    "\n",
    "def split_data_by_age_group(df, var_name):\n",
    "    '''split dataframe by age group'''\n",
    "    df_age_group = pd.DataFrame(df.groupby(var_name)[var_name].count().sort_values(ascending=False))\n",
    "    df_age_group.columns = ['count']\n",
    "    df_age_group.index.name = 'age_group'\n",
    "    return df_age_group\n",
    "\n",
    "def strata_by_age_group(df, group_name, idx):\n",
    "    '''stratify dataframe by label group index'''\n",
    "    df_strata = df[df[group_name] == idx]\n",
    "    return df_strata\n",
    "\n",
    "def resample_data_by_group(df, n_samples):\n",
    "    '''resample data by random replacement'''\n",
    "    sample_group = resample(df, n_samples=n_samples, random_state=0, replace=True)\n",
    "    return sample_group\n",
    "\n",
    "def EDA_feature_importance_plot(model, X, y):\n",
    "    '''plots the feature importance plot on trained model'''\n",
    "    model = model\n",
    "    model.fit(X, y)\n",
    "    feat_labels = X.columns\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
    "    plt.xticks(range(X.shape[1]), feat_labels[indices], rotation=90, fontsize=7)\n",
    "    plt.xlim(-1, X.shape[1])\n",
    "\n",
    "def feature_scale_data(X):\n",
    "    '''Feature scaled data based on standardization'''\n",
    "    sc_X = StandardScaler()\n",
    "    X_std = sc_X.fit_transform(X)\n",
    "    return X_std\n",
    "    \n",
    "# Plot confusion matrix: accuracy, precision, recall and etc.\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    '''plot the confusion matrix of trained model'''\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    cm = cm.astype('float')/cm.sum()\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt='.2f'\n",
    "    thresh = cm.max()/2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i,j], fmt), ha='center', va='center',\n",
    "                    color='white' if cm[i,j] > thresh else 'black')\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.ylabel('true label')\n",
    "\n",
    "# Write report classification metrics summary report\n",
    "def report_class_summary(model_name, y_act, y_pred):\n",
    "    print ('Accuracy of ' + model_name + ' is %0.2f'% skm.accuracy_score(y_act, y_pred))\n",
    "    print ('Precision of ' + model_name + ' is %0.2f'% skm.precision_score(y_act, y_pred))\n",
    "    print ('Recall of ' + model_name + ' is %0.2f'% skm.recall_score(y_act, y_pred))\n",
    "    print ('ROC score of ' + model_name + ' is %0.2f'% skm.roc_auc_score(y_act, y_pred))\n",
    "\n",
    "# Compute confusion matrix:\n",
    "def compute_confusion_matrix(y_act, y_pred):\n",
    "    '''compute sklearn confusion matrix'''\n",
    "    cm_model = skm.confusion_matrix(y_act, y_pred)\n",
    "    return cm_model    \n",
    "\n",
    "def score_model_roc_auc(model, X_train, y_train, X_val, y_val):\n",
    "    '''computes the roc_auc score for probability of being a stroke case'''\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_val)\n",
    "    return skm.roc_auc_score(y_val, probs[:,1])\n",
    "\n",
    "def model_tuning_param(model, feature_df, label_df, param_dist, n_iter):\n",
    "    '''performs RandomizedSearchCV to tune model hyper-parameters'''\n",
    "    random_search = RandomizedSearchCV(model, param_dist, n_iter, cv=5)\n",
    "    random_search.fit(feature_df, label_df)\n",
    "    return random_search\n",
    "\n",
    "def print_best_param(random_search, param_1=None, param_2=None, param_3=None, param_4=None):\n",
    "    '''print the best model parameter(s)'''\n",
    "    print(\"Best \" + param_1 + \":\", random_search.best_estimator_.get_params()[param_1])\n",
    "    print(\"Best \" + param_2 + \":\", random_search.best_estimator_.get_params()[param_2])\n",
    "    print(\"Best \" + param_3 + \":\", random_search.best_estimator_.get_params()[param_3])\n",
    "    print(\"Best \" + param_4 + \":\", random_search.best_estimator_.get_params()[param_4])\n",
    "\n",
    "def model_train(model, feature_df, label_df, n_proc, mean_roc_auc, cv_std):\n",
    "    '''train a model and output mean roc_auc and CV std.dev roc_auc'''\n",
    "    roc_auc = cross_val_score(model, feature_df, label_df, n_jobs=n_proc,\n",
    "                               cv=5, scoring='roc_auc')\n",
    "    mean_roc_auc[model] = np.mean(roc_auc)\n",
    "    cv_std[model] = np.std(roc_auc)    \n",
    "\n",
    "def model_summary(model, mean_roc_auc, cv_std):\n",
    "    '''print out the model performances'''\n",
    "    print('\\nModel:\\n', model)\n",
    "    print('Average roc_auc:\\n', mean_roc_auc[model])\n",
    "    print('Std. Dev during CV:\\n', cv_std[model])    \n",
    "\n",
    "def model_results(model, mean_roc_auc, predictions, feature_importances):\n",
    "    '''saves the model name, mean_roc_auc, predicted rate, and feature importances'''\n",
    "    with open('model.txt', 'w') as file:\n",
    "        file.write(str(model))\n",
    "        feature_importances.to_csv('feat_importances.csv')\n",
    "        predictions.to_csv('pred_results_best.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Load the data --- #\n",
    "if __name__ == '__main__':\n",
    "# Define input CSVs:\n",
    "    train_file = 'stroke_train.csv'\n",
    "    test_file = 'stroke_test.csv'\n",
    "\n",
    "# Define type of variables list:\n",
    "#df_train.select_dtypes(include='object').columns\n",
    "cat_vars = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "#df_train.select_dtypes(include='int64').columns\n",
    "#df_train.select_dtypes(include='float64').columns\n",
    "num_vars = ['hypertension', 'heart_disease', 'age', 'avg_glucose_level', 'bmi']\n",
    "label_var = 'stroke'\n",
    "\n",
    "# Define variables to drop\n",
    "list_vars = 'id'\n",
    "\n",
    "# Load data\n",
    "df_train = load_file(train_file)\n",
    "df_test = load_file(test_file)\n",
    "\n",
    "# Check the metadata of dataframe:\n",
    "df_train.info()\n",
    "\n",
    "# Create a label dataframe:\n",
    "df_label = df_train[['id', 'stroke']]\n",
    "\n",
    "# Drop a column by index: poverty_rate\n",
    "df_train = drop_column_by_index(df_train, label_var)\n",
    "\n",
    "# join train set and label:\n",
    "train_raw_df = join_data(df_train, df_label, key='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Perform data cleaning and quality check --- #\n",
    "# Clean invalid data and duplicates: train and test set\n",
    "\n",
    "\n",
    "# Compute missing value % on a dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check # of missing value counts and percentage ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"Feature 1\" is a categorical feature and about X% of observations are missing.\n",
    "* Followed by \"Feature\" is a numerical feature and about Y% of observations are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Summary Statistics: pre-data cleansing ###\n",
    "Compute summary statistics and report on numerical features only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Explore the data (EDA) --- # \n",
    "# Compute summary statistics\n",
    "\n",
    "# save row_id from test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers with inter-quartile range (IQR) method ###\n",
    "Outliers were required to be managed properly on numerical features. In a training set, there were three independent features (i.e., continuous). These included “age”, “BMI” and “avg_glucose_level”. Interquartile range (IQR) method applied here. For example, if any value of a feature sits below lower and above upper bounds of IQR, these observations will be removed from dataset. \n",
    "\n",
    "IQR is defined as: IQR = Q3 – Q1 in which Q3 is 75th percentile and Q1 is 25th percentile of a feature. Lower bound (LB) equals to Q1 – (1.5*IQR) and upper bound (UB) equals to Q3 + (1.5*IQR).\n",
    "\n",
    "From above definition, summary table was computed on all three numerical features. We can observed that the max. value on each of feature is greater than the upper bound value for average glucose and BMI. Therefore, presence of outliers were confirmed for BMI and average glucose level on beyond upper bound values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 3: handling outliers using IQR #\n",
    "###############################################################################\n",
    "# Compute IQR, LB, UB:        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were outliers on \"Feature 1\" and \"Feature 2\" since max. value of these features are greater than their defined UB values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix plot # \n",
    "###########################\n",
    "\n",
    "# Plot correlation matrix\n",
    "\n",
    "# Compute the correlation of each feature against poverty rate: order of magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding ###\n",
    "Feature encoding is a process where features are encoded into right format. There are two types of feature encoding: ordinal and nominal feature encoding. Ordinal feature encoding is a type of encoding where feature actually contains information about \"order\" like increase or decrease in value (i.e., score level, date, etc). Whereas nominal feature encoding is a type of encoding where feature contains a class of label like gender (i.e., male or female). \n",
    "\n",
    "**Ordinal feature encoding:** smoking_status. \n",
    "Smoking status is a feature where it has an order of smoking level progresses from never smoked to frequent smoker.\n",
    "Thus, smoking status gets mapped into numerical values then gets printed after ordinal feature encoding for checking data consistency.\n",
    "\n",
    "**Nominal feature encoding:** hypertension and heart_disease.\n",
    "These two feature(s) have meaning of different class labels being \"Yes\" or \"No\" but already pre-encoded as numerical value(s) being \"1\" or \"0\". The main reason why these features are re-encoded back into word string is for exploratory data analysis phase. It is best practice to keep data format consistent among same type of variable or feature like \"ever_married\" which is originally contained value as a string \"Yes\" or \"No\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Feature encode on categorical variables --- #\n",
    "# Mapping ordinal and nominal features to integer:\n",
    "\n",
    "\n",
    "# Encode features into to mapping values: train set\n",
    "\n",
    "# Encode features into to mapping values: test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Imputation ###\n",
    "\n",
    "Let's compute feature imputation to replace missing values by following:\n",
    "Mode: smoking_status\n",
    "Mean: bmi (idx: 8, 9)\n",
    "Note: how different types of features were treated by different univariate methods for missing value replacement.\n",
    "\n",
    "First, 'smoking_status' was an ordinal (categorical) feature. Thus, it makes sense to replace missing values by most frequently occurred value (mode).\n",
    "Second, 'bmi' was a numerical feature. Also the feature showed normal distributions upon plotting a histogram. Thus, this can be replaced by mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Feature imputation via univariate techniques --- #    \n",
    "# Split data into input features and target variable #\n",
    "\n",
    "\n",
    "# check input features and target variable: train and test sets\n",
    "\n",
    "# Imputation by mode, mean and median: train and test sets\n",
    "#indices_1 = range(8,9)\n",
    "#indices_2 = range(9,10)\n",
    "\n",
    "# impute bmi and smoking_status by univariate methods: train and test sets\n",
    "\n",
    "\n",
    "# concatenated imputed inputs and output label:\n",
    "\n",
    "# convert smoking_status back to original string:\n",
    "\n",
    "# check any missing values on imputed df:\n",
    "\n",
    "# check cleaned dataframe: data types\n",
    "\n",
    "# Save feature_df for EDA portfolio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering ###\n",
    "Using a groupby function and computing a mean to create a set of new feature(s) from existing feature(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Feature engineering: groupby categorical var ---\n",
    "# Skipped for now #\n",
    "\n",
    "# convert data types for correct metadata: train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding: Dummy Variables ###\n",
    "One-Hot-Encoding on nominal feature allows to create a separate column on each feature and its value are only encoded \"0\" or \"1\". This dummy indicator gets interpreted the ML models for making accurate predictions.\n",
    "\n",
    "Also to reduce any potential biases of having multi-colinearity, each feature's first encoded dummy variable must be dropped to avoid dummy variable trap (i.e., where independent variables are highly inter-correlated with each other as one predictor can be predicted from other of similar variables: gender_female vs. gender_male vs. gender_other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. One-hot-encode on features --- # \n",
    "# Drop first dummy variable to avoid dummy variable trap on each converted feature!\n",
    "\n",
    "\n",
    "# List total number of encoded inputs and output:\n",
    "\n",
    "# Compute label: stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE: Re-Sampling ###\n",
    "A given stroke patient dataset is highly imbalanced where majority of cases were non-stroke (98%) and only 2% (stroke). This is the most common problem for the classifier model which will likely to predict as a non-stroke patient in many cases.\n",
    "\n",
    "Thus, resampling technique was applied to resolve this imbalanced classes posed on this dataset. SMOTE is one of the most common algorithm(s) that are used heavily to resolve this problem. The algorithm can perform over-sampling or down-sampling to increase or decrease the sample size on a specified label (i.e., non-stroke:0, stroke:1). \n",
    "\n",
    "In this case, the over-sampling was performed on the minority class label (i.e., stroke cases) to increase the available sample size for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Compute Proportion (%) of Stroke --- # \n",
    "\n",
    "\n",
    "# --- 11. Resampling on non-stroke patients by non-stroke patients proportion --- # \n",
    "# --- SMOTE: oversample on minority class label --- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 12. Feature seleciton: Feature Importance --- # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 13. Establish a baseline model --- # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 14. Create models --- # \n",
    "# initialize model list and dicts\n",
    "\n",
    "# define common model parameters: num processors and shared model parameters\n",
    "\n",
    "# create and tune the models that you brainstormed during part 2\n",
    "###############################################################################        \n",
    "# Hyper-parameters tuning: Model1\n",
    "\n",
    "\n",
    "# print the best model parameters: Model1    \n",
    "\n",
    "###############################################################################        \n",
    "# Hyper-parameters tuning: Model2\n",
    "\n",
    "# print the best model parameters: Model2    \n",
    "\n",
    "###############################################################################        \n",
    "# Hyper-parameters tuning: Model3\n",
    "\n",
    "# print the best model parameters: Model3    \n",
    "\n",
    "###############################################################################    \n",
    "# Hyper-parameters tuning: Model4\n",
    "\n",
    "# print the best model parameters: Model4    \n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 15. Cross-validate models --- # \n",
    "# 5-fold cross validation on models and measure roc_auc\n",
    "# Model List to train: Order of Model Complexity\n",
    "\n",
    "# List of classifiers:\n",
    "\n",
    "# cross-validate models, using roc_auc to evaluate and print the summaries\n",
    "\n",
    "# --- 16. Select the best model with lowest RMSE for your prediction model --- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: using Feature Selection ###\n",
    "Compute a roc_auc score on \"stroke cases\" for following models:\n",
    "* Logistic Regression\n",
    "* Decision Tree Classifier\n",
    "* Random Forest Classifier\n",
    "* XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 17. Compute roc_auc score on \"stroke cases only!\" --- #\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression ###\n",
    "Logistic regression works by using a logit function to transform input value of features and calculate estimated probabilities of a label in range of [0,1]. For example, if P(1=stroke) ≥ 0.5, an observation is predicted as a stroke. Whereas if P(1=stroke) < 0.5, an observation is predicted as a non-stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Decision Tree ###\n",
    "Decision tree is an algorithm where it predicts the value of a target variable (label) by learning simple decision rules inferred from selected features. Tree is generated and split data on features. It continues to split in repetitive process at each node until leaves reached purity (i.e., remaining samples at each node belongs to same class either non-stroke or stroke cases only)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Random Forest ###\n",
    "Random forest is a typical ensemble learning model. It takes random subsample of data from each tree, so all constructed trees are different from each other. Thus, model makes classification based on predictions made from each tree with averaging (i.e., like picking a vote from majority)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: XGBoost ###\n",
    "XGBoost is a type of gradient boosting model in which subsequent model learns from the mistakes (i.e., residual errors) of previous model in a step-wise forward manner. In Gradient Boosting, residual errors are identified gradients. These gradients help how XGBoost to improve model performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: Confusion Matrix ##\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
    "1. True Positives (TP): These are cases in which model predicted yes (they have the disease), and they do have the disease.\n",
    "2. True Negatives (TN): Model predicted no, and they don't have the disease.\n",
    "3. False Positives (FP): Model predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "4. False Negatives (FN): Model predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 18. Model Evaluation: Confusion Matrix, Classification Metrics ---    \n",
    "# Save cross-validated predictions:\n",
    "\n",
    "\n",
    "# Compute a series of confusion matrix by model:\n",
    "\n",
    "# Define class labels for stroke:\n",
    "\n",
    "#####################################################\n",
    "# Confusion Matrix & Classification Metrics Summary #\n",
    "#####################################################\n",
    "# --- Logistic Regression ---#\n",
    "# Plot a confusion matrix: \n",
    "\n",
    "# Report classification metrics summary:\n",
    "\n",
    "# --- Decision Tree ---#\n",
    "# Plot a confusion matrix: \n",
    "\n",
    "# Report classification metrics summary:\n",
    "\n",
    "# --- Random Forest ---#\n",
    "# Plot a confusion matrix: \n",
    "\n",
    "# Report classification metrics summary:\n",
    "\n",
    "# --- XGBoost Classifier ---#\n",
    "# Plot a confusion matrix: \n",
    "\n",
    "# Report classification metrics summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 19. Model Evaluation: ROC-AUC Curve, Precision-Recall Curve --- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: ROC curve ##\n",
    "ROC curve typically displays true positive rate on the Y-axis, and false positive rate on the X-axis. This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better. The “steepness” of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a ROC-AUC curve\n",
    "\n",
    "# ROC for each classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of ROC Curve ###\n",
    "This plot showed performance of all five models area under the curve. The best model had about AUC = 0.86 for logistic regression model. This indicated that about 88% of time model is good at separation of stroke cases from non-stroke cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: Precision-Recall Curve ##\n",
    "Precision-Recall is a useful measure of success for predictions when the classes of dataset are highly imbalanced. In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned.\n",
    "\n",
    "The precision-recall curve shows the tradeoff between precision and recall at different thresholds. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).\n",
    "\n",
    "In summary, a system with high recall but low precision returns: many predictions where most of prediction results are incorrect when compared to actual true labels. Conversely, a system with low recall and high precision returns: few predictions but most of its prediction results are correct when compared to actual true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a Precision-Recall curve\n",
    "# compute avg. precision score:\n",
    "\n",
    "\n",
    "# Plot a P-R curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Precision-Recall Curve ###\n",
    "Overall, the Logistic Regression showed weighted average precision of 0.08. In other words, about 8% of time, the model is good at making stroke predictions from total # of actual stroke cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 20. Automate the model pipeline --- #\n",
    "# make predictions based on a test set\n",
    "\n",
    "\n",
    "# make predictions dataframe:\n",
    "\n",
    "# --- 21. Deploy the solution --- #\n",
    "#store feature importances\n",
    "\n",
    "# linear models don't have feature_importances_\n",
    "\n",
    "# Create a feature importance dataframe and sort by importance:    \n",
    "\n",
    "# Set index to 'feature'\n",
    "\n",
    "# Create a bar plot:    \n",
    "    \n",
    "#Save model results as .csv file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary: Feature Importance ###\n",
    "A figure showed the feature importance on the best trained model from order of the highest to lowest feature importance ranks.\n",
    "\n",
    "Top 10 important features were age followed by heart_disease_yes, hypertension_yes, never smoked, etc.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
