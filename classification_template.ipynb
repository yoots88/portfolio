{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Portfolio: 'xxx' Classification #\n",
    "\n",
    "This is a data science portfolio for 'xxxx'. The dataset used in this project is a 'xxx'.\n",
    "\n",
    "** Problem Statement: ** \n",
    "The 'xxx' dataset contains various kind of features which helps to indicate the 'xx' for each 'class label'. These include (i.e., )\n",
    "\n",
    "** Stakeholders: ** \n",
    "\n",
    "** Goal: ** \n",
    "Improve 'xx' using classification model\n",
    "* \n",
    "* \n",
    "\n",
    "** Results: ** \n",
    "'x'% of accurate predictions were made on a test set of 'xx' using the 'xxx' classifier.\n",
    "\n",
    "** Risks: ** \n",
    "Model incorrectly identified with 'x'% of error rate (especialy x% error being false negatives (i.e., Type II error)).\n",
    "\n",
    "** Mitigation: ** \n",
    "Reviewed identified error cases with subject matter experts before decision making.\n",
    "\n",
    "** Future Work: ** \n",
    "* \n",
    "\n",
    "** Recommendation for clients: **\n",
    "1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A. Data Wrangling ##\n",
    "A Dataset required data cleansing and metadata formatting. Dataset was loaded onto Python as a dataframe. Dataset presented with a couple of problems such as missing data, outliers and imbalanced classes. In order to clean our dataset and prepared for classification modeling, data cleaning processes were executed. Processes were performed in a following order: feature imputation --> handling outliers --> format metadata types --> feature transformation (i.e., feature encoding). Once dataset was prepared, data exploration and machine learning model buidling exercises were performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from matplotlib.colors import ListedColormap\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check # of missing value counts and percentage ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of missing values and datatypes in dataframe:\n",
    "#df.info()\n",
    "\n",
    "# Compute missing value stat.: pre-data cleansing\n",
    " \n",
    "# sort values by missing percent(%):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, there were couple of features missing more than 50% of data (threshold). \n",
    "These features need to be removed from the entire dataset.\n",
    "\n",
    "Numerical feature(s) with missing values:\n",
    "* feature 1: x%\n",
    "* feature 2: x%\n",
    "\n",
    "Categorical feature(s) with missing values:\n",
    "* feature 1: x%\n",
    "* feature 2: x%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Summary Statistics: pre-data cleansing ###\n",
    "Computer summary statistics and report on numerical features only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary stat.: pre-data cleansing #\n",
    "###############################################################################\n",
    "# Note: NO stats computed for categorical variables (nominal & ordinal features)\n",
    "\n",
    "# Reorder columns in following order: count to std\n",
    "\n",
    "# Drop all categorical features: keep only numerical\n",
    "\n",
    "# Print summary stat:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop features with missing values more than 50% ###\n",
    "It is important drop any features where missing values counts % is far greater than 50%. Even though these features can be imputed by missing value replacement, it will not provide meaningful insights rather offer undesirable biased results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features where missing_pct (%) > 50%:\n",
    "###############################################################################\n",
    "# Boolean which feature are missing more than 50%:\n",
    "\n",
    "# Drop 4 features with more than 50% missing values:\n",
    "\n",
    "# Check dataframe:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers with inter-quartile range (IQR) method ###\n",
    "Outliers are the values that might potentialy skew the results on our modeling. In order to maximize the performance of classification model(s), it is required to handle outliers first. In a training set, there are 14 numerical features and a outlier detection dataframe was created. Easily, it was easy to identify there were outlier(s) in \"distance\" and \"avg. income\". The maximum value on each of feature is greater than the upper bound value computed IQR method. \n",
    "\n",
    "Outliers were required to be managed properly on these numerical features. In a training set, there were 10 independent features (i.e., continuous). These included “avg_income”, “distance” and etc. Interquartile range (IQR) method applied here. For example, if any value of a feature sits below lower and above upper bounds of IQR, these observations will be removed from dataset.\n",
    "\n",
    "**IQR is defined as: IQR = Q3 – Q1 in which Q3 is 75th percentile and Q1 is 25th percentile of a feature. Lower bound (LB) equals to Q1 – (1.5 x IQR) and upper bound (UB) equals to Q3 + (1.5 x IQR)**.\n",
    "\n",
    "From above definition, summary table was computed on all three numerical features. We can observed that the max. value on each of feature is greater than the upper bound value for avg_income, distance etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outliers #\n",
    "# Compute IQR, LowerBound and UpperBound\n",
    "\n",
    "# Extract dataframe:\n",
    "\n",
    "# How many features have outliers from Upper Bound (TRUE): x # of features\n",
    "\n",
    "# How many features have outliers from Lower Bound (TRUE): x # of feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From Upper Bound perspective, presence of outliers were detected on 'x' numerical features: \n",
    "* From Lower Bound perspective, presence of outliers were detected on 'x' numerical feature:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of outliers and drop useless feature ###\n",
    "Before remove outliers on these features, test how many observations are affected.\n",
    "This is critical because while removing outliers we want to preserve positive \"positive class label\" samples as many as possible. More true positive cases you have, better for training a model and make good predictions on future xxx cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test removing outliers: \n",
    "# feature 1: drop = 'x' # of rows\n",
    "# feature 2: drop = 'x' # of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding ###\n",
    "Feature encoding is a process where feature are encoded into right format. There are two types of feature encoding: ordinal and nominal feature encoding. Ordinal feature encoding is a type of encoding where feature actually contains information about \"order\" like increase or decrease in value (i.e., score level, date, etc). Whereas nominal feature encoding is a type of encoding where feature contains a class of label like gender (i.e., male or female). \n",
    "\n",
    "** Nominal feature encoding: ** allergy and previous_medication.\n",
    "These two feature(s) have meaning of different class labels being \"Yes\" or \"No\" but already pre-encoded as numerical value(s) being \"1\" or \"0\". The main reason why these feature getting re-encoded back into word string is for exploratory data analysis phase. It is best practice to keep data format consistent and convert for easier interpretation when perfoming data exploration like a string value of \"Yes\" or \"No\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Nominal feature encoding:\n",
    "###########################\n",
    "# Define manual map: Gender_map\n",
    "Gender_map = {0:'Female', 1:'Male'}\n",
    "# Define manual map: Yes_No_map\n",
    "Yes_No_map = {0:'No', 1:'Yes'}\n",
    "\n",
    "# Inverse transform back to original value map:\n",
    "inv_Gender_map = {v: k for k, v in Gender_map.items()}\n",
    "inv_Yes_No_map = {v: k for k, v in Yes_No_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Ordinal feature encoding: ** admission_date. \n",
    "Admission date is a feature where it has a order of admission date from year 2009 to 2014. Thus, Admission date gets mapped into numerical values. For checking format of data consistency, we will print transformed admission date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Ordinal feature encoding:\n",
    "###########################\n",
    "#  #\n",
    "###############################################################################\n",
    "\n",
    "# Use mapping to transform the 'xxx' into integers:\n",
    "\n",
    "# Reverse key-value pairs in the mapping dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splits & Feature Transformation ###\n",
    "First, dataset was split into a set of input features and an output label (i.e., admit). Secondly, feature imputation step was performed to replace any missing values on different data types (i.e., continuous and ordinal feature). For example, \"feature 1\" and \"feature 2\" were replaced by median and mode respectively. Finally, metadata formatting was done to ensure each feature for having a correct data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Feature Imputation:\n",
    "###########################\n",
    "# feature 1:\n",
    "###############################################################################\n",
    "# counts='x', Mode = 'z'\n",
    "\n",
    "# feature 2:\n",
    "###############################################################################\n",
    "# counts='x', Mode = 'z'\n",
    "\n",
    "# Missing Value Replacement: Nominal Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify inputs and output label:\n",
    "\n",
    "# Rename Y as column name 'class label':\n",
    "\n",
    "# Missing value check:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped features for index\n",
    "###############################################################################\n",
    "# Column index = x1, \n",
    "# Column index = x2, \n",
    "\n",
    "# Feature Imputation #\n",
    "###############################################################################\n",
    "# Imputation: feature 1, feature 2 (scale feature) by median\n",
    "# Column index = \n",
    "\n",
    "# Imputation: feature 3 (categorical feature) by mode\n",
    "# Column index = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare cleansed dataframe:\n",
    "# Column indexes \n",
    "\n",
    "# Row indexes\n",
    "\n",
    "# Cleansed dataframe:\n",
    "\n",
    "# Concatenated X1 cleaned inputs and output label as new dataframe:\n",
    "\n",
    "# Check any missing values on a new dataframe:\n",
    "\n",
    "# Convert data types for cleaned dataframe:\n",
    "\n",
    "# Check data type:\n",
    "\n",
    "# Save cleaned dataframe for ML modeling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-817aadb189cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Save cleaned dataframe for EDA:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf_cleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ED_train_cleaned.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "# Keep df_cleaned dataframe for Exploratory Data Analysis (EDA) #\n",
    "###############################################################################\n",
    "# Encode features on feature 1, feature 2: string values\n",
    "\n",
    "# Encode admission date back to original format:\n",
    "\n",
    "# Check final dataframe format:\n",
    "\n",
    "# Save cleaned dataframe for EDA:\n",
    "df_cleaned.to_csv('ED_train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B. Exploratory Data Analysis ##\n",
    "\n",
    "### EDA: cleaned train set ###\n",
    "Data exploration is conducted on cleaned entire train set. The main goal of this phase is to explore any interesting relationships among features and identify which feature has a clear impact on predicting ED admitted cases over an ED non-admitted patient. \n",
    "\n",
    "Following set of questions are asked:\n",
    "1. Can I count something interesting?\n",
    "2. Can I find some trends (increase or decrease and any anomalies)?\n",
    "3. Can I plot a bar chart or a histogram?\n",
    "4. Can I make a scatter plot?\n",
    "\n",
    "These set of guiding questions will help us to explore any insights and tells a compelling story about stroke classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of missing values:\n",
    "\n",
    "# Check drop duplicates: drop 'x' rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Part B: Exploratory Data Analysis #\n",
    "###############################################################################\n",
    "# Compute summary stat.: post-data cleansing \n",
    "\n",
    "# Reorder columns order in summary dataframe\n",
    "\n",
    "# drop non-numerical and meaningless features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequencies and shows breakdown by class label:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data frames: grouping on ED admit flag by demographics and diagnostic factors ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequencies: demographic factors on 'dataset name'\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency counts class label 1 vs label 2: by demographic factors ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion: only class label1 by 'categorical feature 1'\n",
    "\n",
    "# Proportion: only class label2 by 'categorical feature 1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Histogram: Continous Varaibles***\n",
    "\n",
    "Distribution of feature 1, feature 2 and feature 3 of dataset. Distributions were plotted separately on same kind of figure for each group of 'class label 1' and 'class label 2' population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped dataframe by class label:\n",
    "\n",
    "# Visualization: continuous/discrete - scale\n",
    "###############################################################################\n",
    "# Histogram: feature 1\n",
    "#df['feature name'].hist(bins=, label=df['label'])\n",
    "_ = plt.title('')\n",
    "_ = plt.xlabel('')\n",
    "_ = plt.ylabel('Number of ')\n",
    "_ = plt.legend(('label 1','label 2'), loc='upper right')\n",
    "_ = plt.show()\n",
    "\n",
    "# Histogram: feature 2\n",
    "\n",
    "# Histogram: feature 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of distributions by feature 1, feature 2 and feature 3\n",
    "* feature 1: distribution of 'xxx' on 'label 1' population is skewed to right. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix: Training Set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix Plot # entire dataset\n",
    "###############################################################################\n",
    "# Column names of cleaned dataframe\n",
    "\n",
    "# Plot correlation matrix heatmap\n",
    "#plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Whisker Plot: entire dataset (label 1 vs. label 2) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: categorical and scale \n",
    "# Box-Whisker Plot #\n",
    "_ = plt.figure() # inside plt.figure(), figsize = (x,y)\n",
    "_ = plt.title('')\n",
    "_ = sns.boxplot(x = '', y = '',  data = )\n",
    "xt = plt.xticks(rotation=, fontsize=)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA: class label 2 only ###\n",
    "### Correlation Matrix Plot: true positive class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered dataframe by class label: '0':, '1': #\n",
    "###############################################################################\n",
    "\n",
    "# Correlation Matrix Plot #\n",
    "# CM plot of 'class label 2' only:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar charts: number of class label 2 cases by demographic factors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar charts on 'xxx' factors on class label 2 cases #\n",
    "plt.figure()\n",
    "sns.countplot(x='', hue='', data=)\n",
    "plt.ylabel('')\n",
    "plt.legend(('',''), loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar charts: mean 'importance numerical feature' of class label 2 by demographic factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: categorical data #\n",
    "# Convert labels into text label:\n",
    "#x = [0,1]\n",
    "#labels=['class 0','class 1']\n",
    "\n",
    "# Mean 'feature 1' factored by \"class label\" flag:\n",
    "#df_cleaned.groupby('label')['feature 1'].mean().sort_values(ascending=False).plot(kind='bar')\n",
    "#plt.xlabel('')\n",
    "#plt.ylabel('')\n",
    "#plt.xticks(x, labels, rotation=0)\n",
    "#plt.title('Mean feature 1 of cases by label')\n",
    "#plt.show()\n",
    "\n",
    "# Normalized mean 'feature 2' factored by \"class label\" flag:\n",
    "#(df_cleaned.groupby('label')['feature 1'].mean()/mean_value).sort_values(ascending=False).plot(kind='bar')\n",
    "#plt.xlabel('')\n",
    "#plt.ylabel('')\n",
    "#plt.xticks(x, labels, rotation=0)\n",
    "#plt.title('Mean feature 2 of cases by label')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Summary Statistics: label 1 vs label 2 cases ###\n",
    "Computer summary statistics and report on numerical features only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics #\n",
    "###############################################################################\n",
    "# label 1 cases only:\n",
    "\n",
    "# Reorder columns order in summary dataframe\n",
    "\n",
    "# Drop 'label' column if encoded as numerical:\n",
    "\n",
    "# Print summary stat.:\n",
    "\n",
    "\n",
    "# label 2 cases only:\n",
    "\n",
    "# Reorder columns order in summary dataframe\n",
    "\n",
    "# Drop 'label' column if encoded as numerical:\n",
    "\n",
    "# Print summary stat.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with class imbalance problem on 'name' dataset ###\n",
    "Class imbalance with low prevalence of true positive cases (i.e., 'label 2' cases) are the most common problem in 'xxx industry' for any classification problems. For example, in this dataset, x% were 'label 1' and only x% were 'label 2' cases. Thus, if class imbalance in the dataset is not handled properly, a classifier would ended up predicting \"label 1\" cases most of time. Therefore, even if the ML model's has high accuracy (due to true negative: label 1 cases), the trained classifier is not going to be meaningful for making good predictions.\n",
    "\n",
    "Class imbalance adjustment is addressed here by executing random downsampling on population of 'label 1' cases to match the sample size of 'label 2' population. This will help builiding a classifier with equal proportion of classes (i.e., label 1 and label 2) with higher prevalence (i.e., 50% of 'label 2' cases present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling on label 1 sample to match proportion of label 2 cases:\n",
    "######################################################################################\n",
    " # downsampled = resample(df_label1, replace=True,\n",
    " #                        n_samples='x',random_state='z')\n",
    "\n",
    "# Combine minority class '1': stroke patients with downsampled majority class:\n",
    " # df_2 = pd.concat([downsampled, df_label2], axis=0)\n",
    "\n",
    "# Check # of class label: admit vs. non-admit\n",
    " #df['label'].value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downsampling, the resampled dataset achieved an equal ratio of stroke and non-stroke cases with a sample size (n=4288)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA: balanced dataset with negative sub-sampling (downsampled) ###\n",
    "### Correlation Matrix Plot: class label 2 (downsampled) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix Plot # random downsampled dataset (1:1 ratio)\n",
    "###############################################################################\n",
    "# CM plot of randomized downsampled dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Analysis: Balanced Dataset (downsampled) ###\n",
    "To further explore a pair of relationships between 'feature 1' and 'feature 2', 'feature 2' and feature 3' pairs, linear regression analyses were performed on resampled dataset. Relationship(s) will be explored by using an \"class\" label as condition for faceted scatter plots. Thus, we are going to analyze this trend by calculating Pearson's r correlation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split feature 1, feature 2 and etc. into different population groups:\n",
    "# class label 1 group: \n",
    "# df_resampled[df_resampled['label'] == 0]['feature 1']\n",
    "# df_resampled[df_resampled['label'] == 0]['feature 2']\n",
    "\n",
    "# class label 2 group: \n",
    "# df_resampled[df_resampled['label'] == 1]['feature 1']\n",
    "# df_resampled[df_resampled['label'] == 1]['feature 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Define Pearson Correlation Function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(x,y):\n",
    "    corr_mat = np.corrcoef(x,y)\n",
    "    return corr_mat[0,1]\n",
    "\n",
    "# Compute Pearson correlation coefficient: class label 1 population\n",
    "\n",
    "# Compute Pearson correlation coefficient: class label 2 population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faceted Scatter Plot: by class labels\n",
    "Plot relationship(s) between feature 1 and other 3 features by Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Plot a scatter plot: feature 1 vs. feature 2\n",
    "##################################################################\n",
    "\n",
    "# Fit a linear regression model:\n",
    "\n",
    "# Theoretical best line of fit:\n",
    "\n",
    "# Plot a line of best fit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Linear Regression Analysis ###\n",
    "* Faceted by an admit flag: a scatter plot faceted by ED admission flag showed weak correlations between GP visits and MRI count. For ED admitted cases, Pearson correlation value was r=0.20. In contrast, for non-ED admitted cases, Pearson correlation value was r=0.28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C. Machine Learning Modeling: Classification ##\n",
    "\n",
    "### Dummy Variable Encoding: nominal features ###\n",
    "Dummy variable encoding on nominal feature allows to create a separate column on each feature and its value are only encoded \"0\" or \"1\". This dummy indicator gets interpreted by ML models for making accurate predictions. Also to reduce any potential biases of having multi-colinearity, each feature's first encoded dummy variable must be dropped to avoid dummy variable trap (i.e., where independent variables are highly inter-correlated with each other as one predictor can be predicted from other of similar variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode features on Gender, Allergy, Family_History:\n",
    "\n",
    "# Encode admission date to ordinal format:\n",
    "\n",
    "# Check re-formatted on random down resampled dataframe:\n",
    "\n",
    "# Check unique entities on following categorical features:\n",
    "\n",
    "# Dummy Variable Encoding: nominal features #\n",
    "###############################################################################\n",
    "# Omit 'GP Code': 1st it is not meaningful feature. 2nd it contains too many entities and generate new dummy variables. \n",
    "\n",
    "# Drop first dummy variable on each nominal feature to avoid dummy variable trap:\n",
    "\n",
    "# Concatenate dummy variable encoded dataframe and admit (output) label together:\n",
    "\n",
    "# Print top & bottom 5 observations:\n",
    "\n",
    "# Check dataframe info.:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on input features and output label ###\n",
    "For 'xxx' problem, following set of classifiers were tested which included logistic regression, decision tree, random forest and gradient boosting (XGBoost).\n",
    "\n",
    "After each model construction, RandomizedSearchCV module was applied to tune hyperparameters (i.e., C, n_estimators, etc.) on each model. This boosted model helps us to achieve the best desired performance for making predictions on 'xxx'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# QA check on input features/class label #\n",
    "# Re-define input features and output label:\n",
    "\n",
    "# Print unique labels for ED admission:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partition & Feature Scaling ###\n",
    "* First is data partition step. It is an absolute requirement procedure in which split original data into training and test sets for training and evaluation of any machine learning modeling task.\n",
    "\n",
    "* Second is a feature scaling where different ranges of feature inputs feed into a scaler function (i.e., min-max, logarithmic, etc.). This function will re-scale them into a similar range on each feature. This helps some classification model(s) to handle importance of features in a normalized fashion. Feature scaling was applied before the classification models were constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# General: data parition - train vs. test set\n",
    "# Use built-in stratify mode to ensure equal % label splits\n",
    "\n",
    "# Check label counts on the split set:\n",
    "\n",
    "# Feature Scaling: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Recursive Feature Elimination #\n",
    "# Using Logistic Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression ###\n",
    "Logistic regression is an algorithm where input features get transformed via the sigmoid logit function: odds ratio of logarithmic probabilty of an event occurring (i.e., ED admitted cases over non-ED admitted cases). Thus, output value will be ranged from (0,1). Logistic regression works well on linearly separable classes problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Model 1: Logistic Regression #\n",
    "################################\n",
    "###############################################################################\n",
    "# Feature Selection by LogisticReg + RFE #\n",
    "# Reduced features: \n",
    "    \n",
    "# K-fold Cross-validation: Stratified #\n",
    "# Logistic Regression:\n",
    "#   print(\"TRAIN:\", train_index,  \"VALIDATE:\", val_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Logistic Regression\n",
    "\n",
    "# Hyperparameters Tuning:\n",
    "###############################################################################\n",
    "# RandomizedSearchCV: LogisticRegression #\n",
    "# Create hyperparameter options:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Model prediction: hold-out test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: K-Nearest Neighbors (K-NN) ###\n",
    "K-NN is a non-parametric lazy learning algorithm. Where it uses pattern in data to place new data points for relevant categories/classes. The algorithm works by performing calculation of Euclidean distance between existing points and new data point. Thus, assigns new data point to a class with most k-Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Model 2: K-Nearest Neighbors #\n",
    "################################\n",
    "###############################################################################\n",
    "# Using K-NN model: \n",
    "# Reduced features:  \n",
    "    \n",
    "# K-fold Cross-validation: Stratified #\n",
    "# K-NN:\n",
    "\n",
    "# Model: K-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Tuning:\n",
    "###############################################################################\n",
    "# RandomizedSearchCV: K-NN #\n",
    "# Create hyperparameter options:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Model prediction: hold-out test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Support Vector Machine (SVM) ###\n",
    "SVM is a type of marginal classifier algorithm. The main objective of this algorithm is to draw decision boundary between two hyperplanes (positive and negative) to classify class label(s) of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Model 3: Support Vector Machine #\n",
    "###################################\n",
    "###############################################################################\n",
    "# Using SVM model: \n",
    "\n",
    "# Reduced features: \n",
    "    \n",
    "# K-fold Cross-validation: Stratified #\n",
    "# SVM:\n",
    "\n",
    "# Model: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Tuning:\n",
    "###############################################################################\n",
    "# RandomizedSearchCV: SVM #\n",
    "# Create hyperparameter options:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Model prediction: hold-out test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Decision Tree ###\n",
    "Decision tree is an algorithm where it predicts the value of a target variable (label) by learning simple decision rules inferred from selected features. A tree is generated and split data on features. It continues to split in repetitive process at each node until leaves reached purity (i.e., remaining samples at each node belongs to same class either non-ED admitted or ED admitted cases only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Feature Selection: Feature Importance #\n",
    "# Using a Decision Tree: Top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Model 4: DecisionTree Classifier #\n",
    "####################################\n",
    "# Feature Selection by DT Classifier: \n",
    "\n",
    "# K-fold Cross-validation: Stratified #\n",
    "# DecisionTree Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: DecisionTree [cross-validated & std. train set]\n",
    "\n",
    "# Hyperparameters Tuning:\n",
    "###############################################################################\n",
    "# Create hyperparameter options:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Model prediction: CV testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Random Forest ###\n",
    "Random forest is a typical ensemble learning model. It takes random subsample of data from each tree, so all constructed trees are different from each other. Thus, model makes classification based on predictions made from each tree with averaging (i.e., like picking a vote from majority)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Feature Selection: Feature Importance #\n",
    "# Using a Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Model 5: RandomForest Classifier #\n",
    "####################################\n",
    "# Feature Selection by RF Classifier: \n",
    "\n",
    "# K-fold Cross-validation: Stratified #\n",
    "# RandomForest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: RandomForest [cross-validated & std. train set]\n",
    "\n",
    "# Hyperparameters Tuning:\n",
    "###############################################################################\n",
    "# Create hyperparameter options:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Model prediction: CV testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: XGBoost ###\n",
    "XGBoost is a type of gradient boosting model in which subsequent model learns from the mistakes (i.e., residual errors) of previous model in a step-wise forward manner. In Gradient Boosting, residual errors are identified gradients. These gradients help how XGBoost to improve model performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Model 6: XGBoost Classifier #\n",
    "####################################\n",
    "# Feature Selection: Feature Importance #\n",
    "###############################################################################\n",
    "# Using a XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection by XGB Classifier: \n",
    "\n",
    "# K-fold Cross-validation: Stratified #\n",
    "# XGB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: XGBClassifier [cross-validated & std. train set]\n",
    "\n",
    "# Hyperparameters Tuning:\n",
    "###############################################################################\n",
    "# Create hyperparameter options:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Model prediction: hold-out test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary: ML Classifications ###\n",
    "Visualize decision boundaries for top two selected features on all six classifiers. Following decision boundary plots were plotted to show how well 'class label 2' cases were separated from 'class label 1' cases:\n",
    "\n",
    "* Logistic Regression: feature 1 vs. feature 2 [standardized]\n",
    "* K-Nearest Neighbors: feature 1 vs. feature 2 [standardized]\n",
    "* Support Vector Machine: feature 1 vs. feature 2 [standardized]\n",
    "* Decision Tree: feature 1 vs. feature 2 [standardized]\n",
    "* Random Forest: feature 1 vs. feature 2 [standardized]\n",
    "* XGBoost: feature 1 vs. feature 2 [standardized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Decision Boundary Plots: ML Classifiers #\n",
    "###########################################\n",
    "# Write plot_decision_regions function #\n",
    "    # Setup marker generator and colormap\n",
    "    \n",
    "    # Plot decision surface\n",
    "\n",
    "# Visualize stroke classification: Logistic Regression #\n",
    "###############################################################################\n",
    "# hold-out test set\n",
    "\n",
    "# Visualize stroke classification: K-Nearest Neighbors #\n",
    "###############################################################################\n",
    "# hold-out test set\n",
    "\n",
    "# Visualize stroke classification: Support Vector Machine #\n",
    "###############################################################################\n",
    "# hold-out test set\n",
    "\n",
    "# Visualize stroke classification: Decision Tree #\n",
    "###############################################################################\n",
    "# hold-out test set\n",
    "\n",
    "# Visualize stroke classification: Random Forest #\n",
    "###############################################################################\n",
    "# hold-out test set\n",
    "\n",
    "# Visualize stroke classification: XGBoost #\n",
    "###############################################################################\n",
    "# hold-out test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: Confusion Matrix ##\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
    "\n",
    "1. True Positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "2. True Negatives (TN): We predicted no, and they don't have the disease.\n",
    "3. False Positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "4. False Negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion/Contingency Matrix #\n",
    "#############################################################################\n",
    "# Write plot_confusion_matrix function #\n",
    "        \n",
    "    #plt.tight_layout()\n",
    "\n",
    "\n",
    "# Make class labels for \"admit flag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on test set: Logistic Regression\n",
    "###############################################################################\n",
    "\n",
    "# Classification metrics on test set: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on test set: K-Nearest Neighbors\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Classification metrics on test set: KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on test set: Support Vector Machine\n",
    "###############################################################################\n",
    "\n",
    "# Classification metrics on test set: SupportVectorMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on test set: DecisionTree\n",
    "###############################################################################\n",
    "\n",
    "# Classification metrics on test set: DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on test set: RandomForest\n",
    "###############################################################################\n",
    "\n",
    "# Classification metrics on test set: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix on test set: XGBoost\n",
    "###############################################################################\n",
    "\n",
    "# Classification metrics on test set: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: precision-recall curve ###\n",
    "Precision-Recall is a useful measure of success for predictions when the classes of dataset are highly imbalanced. In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned.\n",
    "\n",
    "The precision-recall curve shows the tradeoff between precision and recall at different thresholds. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).\n",
    "\n",
    "In summary, a system with high recall but low precision returns: many predictions where most of prediction results are incorrect when compared to actual true labels. Conversely, a system with low recall and high precision returns: few predictions but most of its prediction results are correct when compared to actual true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Model Evaluation: Precision Recall Curve #\n",
    "############################################\n",
    "# Compute average precision score: best model\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Plot Precision-Recall curve:\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Precision-Recall Curve ###\n",
    "Overall, the 'xxx' classifier showed the best weighted average precision of 0.xx. In other words, about x% of time, the model is good at making 'name of dataset' predictions from total # of actual 'class label 2' cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: ROC curve ###\n",
    "ROC curve typically displays true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better. The “steepness” of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Model Evaluation: ROC-AUC Curve #\n",
    "###################################\n",
    "# All labels and trained classifiers # \n",
    "######################################\n",
    "\n",
    "# Plot a ROC Curve #\n",
    "#####################################\n",
    "# ROC for each classifiers\n",
    "        # Asumming the label of the positive class is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of ROC Curve ###\n",
    "Overall, top x classifiers showed mean AUC of 0.xx. These models were 'model 1' and 'model 2' classifiers. In summary, about x% of time these models were good at separating 'class label 2' predictions fron 'class label 1' predictions ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
