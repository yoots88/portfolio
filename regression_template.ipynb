{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio: 'Title' ##\n",
    "This is xxx. The dataset was collected to xxx. It can be found in xxx.\n",
    "\n",
    "#### Problem Statement: \n",
    "The xxx dataset contains x numerical features and one target/response variable. These include xxx features (i.e., )\n",
    "\n",
    "#### Stakeholders: ### \n",
    "\n",
    "#### Goal: ###\n",
    "\n",
    "#### Results: ###\n",
    "\n",
    "#### Risks: ###\n",
    "\n",
    "#### Mitigation: ### \n",
    "\n",
    "#### Future Work: ###\n",
    "\n",
    "#### Recommendation for clients:\n",
    "* 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A. Data Wrangling ##\n",
    "A Dataset required data cleansing and metadata formatting. Dataset was loaded onto Python as a dataframe. Dataset presented with a couple of problems such as missing data, outliers and imbalanced classes. In order to clean our dataset and prepared for regression modeling, data cleaning processes were executed. Processes were performed in a following order: feature imputation --> handling outliers --> format metadata types --> feature transformation (i.e., feature encoding). Once dataset was prepared, data exploration and machine learning model buidling exercises were performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import scipy.stats as sp\n",
    "import pylab "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B. Exploratory Data Analysis ##\n",
    "\n",
    "#### Boston Housing: training set ###\n",
    "Data exploration is conducted on cleaned entire trainng set. The main goal of this phase is to explore any interesting relationships among features and identify which feature are good predictors for predicting housing prices.\n",
    "\n",
    "Following set of questions are asked:\n",
    "* 1) Can I count something interesting?\n",
    "* 2) Can I find some trends (increase or decrease and any anomalies)?\n",
    "* 3) Can I plot a bar chart or a histogram?\n",
    "* 4) Can I make a scatter plot?\n",
    "\n",
    "These set of guiding questions will help us to explore any insights and tells a compelling story about housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform summary statistics\n",
    "\n",
    "# Print summary stat:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Univariate Analysis: continuous numeric features (scale) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Univariate analysis: continuous features [scale]\n",
    "###############################################################################\n",
    "# feature 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:  ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:  ####\n",
    "* 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C. Machine Learning: Regression Analysis ##\n",
    "Here, \n",
    "Y  = boston housing prices (called \"target\" data in python, and referred to as the dependent variable or response variable) and\n",
    "X  = all the other features (or independent variables, predictors or explanatory variables)\n",
    "\n",
    "which we will use to fit a linear regression model and predict Boston housing prices. We will use the least-squares method to estimate the coefficients.\n",
    "\n",
    "We will compare different types of regression modeling available on scikit-learn and statsmodel OLS:\n",
    "* Linear Regression\n",
    "* Multiple Linear Regression\n",
    "* Polynomial Regression\n",
    "* DecisionTree Regression\n",
    "* RandomForest Regression\n",
    "* XGBoost Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on input features and target variable  ###\n",
    "For xxx problem, following set of regressors were tested which included linear regression, multi-linear, polynomial, decision tree, random forest and gradient boosting (XGBoost).\n",
    "\n",
    "After each model construction, RandomizedSearchCV module was applied to tune hyperparameters (i.e., C, n_estimators, etc.) on each model. This boosted model helps us to achieve the best desired performance for making predictions on housing price with least RMSE and max R^2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split input features and output (target) variable:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: using L1 regularization (LASSO) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection Testing: L1 Regularization (LASSO) #\n",
    "###############################################################################\n",
    "# Fit L1 regularization to figure out non-zero coefficients:\n",
    "\n",
    "# Print estimated intercept coefficient:\n",
    "\n",
    "# Feature selection dataframe: using L1 fitted coefficients\n",
    "\n",
    "# Feature Selection: top selected features by L1 (LASSO)\n",
    "# EstCoef: \n",
    "# Indexes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: L1 Regualarized Coefficients (LASSO) ####\n",
    "In summary, since any features with zero coefficients are useless, it is best to use any non-zero coefficients as a set of input features for building a good regression model. \n",
    "\n",
    "Useless features were detected as follow:\n",
    "* 1) feature 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1. OLS stasmodel: Multiple Linear Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Test: statsmodel Multiple LinearRegression # \n",
    "##############################################\n",
    "# Compute linear regression: RM\n",
    "\n",
    "# Compute multi-linear regression: 3 features\n",
    "\n",
    "# Compute multi-linear regression: 5 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: using OLS model to compare regression models ####\n",
    "The aim of this section is to compare model performance across all 3 OLS models that we built. 1st model was built using only x. 2nd model was built using 3 predictors (i.e., xxx, xx, x). Finally, 3rd model was built using 5 predictors (i.e., xxx). \n",
    "\n",
    "Overall, the 3rd model provided the best adjusted R-squared value of 0.xxx and the least AIC value of xxxx as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot: by OLS stats model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot by OLS model  #\n",
    "##############################\n",
    "# Evaluation 0: Scatter Plot #\n",
    "##############################\n",
    "# Plot: Predicted vs original housing price\n",
    "plt.figure()\n",
    "_ = plt.scatter(x, y,\n",
    "            c='blue', edgecolor='w', marker='o')\n",
    "_ = plt.title('')\n",
    "_ = plt.xlabel('')\n",
    "_ = plt.ylabel('')\n",
    "_ = plt.legend(loc='upper left')\n",
    "_ = plt.show()\n",
    "\n",
    "###############################\n",
    "# Evaluation 1: Residual Plot #\n",
    "###############################\n",
    "# Plot: Residuals vs. predicted price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: scatter plots of OLS models ####\n",
    "First scatter plot shows \n",
    "\n",
    "Second scatter plot shows difference in original - predicted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partition & Feature Scaling ###\n",
    "* First step is data partition. It is an absolute requirement procedure in which split original data into training and test sets. Thus, it aims to separate data for model training and model perfomance evaluation.\n",
    "* Second step is a feature scaling in which a scaler function (i.e., min-max, logarithmic, etc.) standardize different range of features into a close proximity (i.e., ranges). This helps some regression model(s) to handle importance of features in a normalized equal weighted fashion. Feature scaling was applied before training different kinds of regression algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set and test set:\n",
    "###############################################################################\n",
    "\n",
    "# Apply Feature Scaling: using StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Test: RANSAC model to filtrate potential outliers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Viz Test: outliers using RANSAC model #\n",
    "#########################################\n",
    "# Feature average room/dwelling without scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: RANSAC fitted model of scatter plot ####\n",
    "Using RANSAC fitted model, we can visually inspect inliers and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Analysis Plot Function: scatter plots + line of best fit ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function: scatter plot + model fitted REG line\n",
    "def lin_regplot(X, y, model):\n",
    "#    plt.scatter() # (x, y, c, edgecolor, s)\n",
    "#    plt.plot() #(x, predict, color, lw)\n",
    "\n",
    "# Define input features: 1 predictor (RM)\n",
    "\n",
    "# Fit Linear Regressor()\n",
    "####################################################################\n",
    "# Fit a simple Linear Regression:\n",
    "\n",
    "# Check original price\n",
    "\n",
    "# Plot RM vs Housing Price:\n",
    "####################################################################\n",
    "\n",
    "# Fit Polynomial Regressor()\n",
    "####################################################################\n",
    "# Fit a simple Linear Regression:\n",
    "\n",
    "# Fit a quad Polynomial Linear Regression:\n",
    "\n",
    "# Plot: Linear vs. Polynomial Regression Comparision\n",
    "####################################################################\n",
    "\n",
    "# Fit DecisionTree Regressor():\n",
    "####################################################################\n",
    "\n",
    "# Fit RandomForest Regressor():\n",
    "####################################################################\n",
    "\n",
    "# Fit XGBoost Regressor():\n",
    "####################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: regression analyses on regression models ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation ###\n",
    "Using L1 selected features, k-fold cross validation approached will be used for model training and optimize model hyperparameters. Firstly, earlier training set portition was used to divde data into multiple folds. In each iteration, one fold was used as validation for optimizing model parameters and remaining folds were used for model training. Note that this procedure will be repeated \"k\" times as we specified where each validation fold shuffled between iterations. Finally, overal model performance would be average across all iterations to provide the best model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features: using L1 regualarization\n",
    "\n",
    "# Apply cross-validation: with K-Fold to divide \"K\" groups of samples for optimize model hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation: using L1 selected features ###\n",
    "Compute RMSE, R^2, scatter plot: original vs. predicted and residuals plot of following regression models:\n",
    "* Linear Regression\n",
    "* Multiple Linear Regression\n",
    "* Polynomial Regression\n",
    "* DecisionTree Regression\n",
    "* RandomForest Regression\n",
    "* XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Model 1. LinearRegression() #\n",
    "###############################\n",
    "# Apply LinearRegression: \n",
    "\n",
    "# Make prediction: feature scaled inputs\n",
    "\n",
    "##############################\n",
    "# Evaluation 0: Scatter Plot #\n",
    "##############################\n",
    "# Scatter Plot: original vs. predicted price\n",
    "\n",
    "###############################\n",
    "# Evaluation 1: Residual Plot #\n",
    "###############################\n",
    "# Plot: Residuals vs. predicted price\n",
    "\n",
    "# Compute RMSE: training & test set:\n",
    "\n",
    "# Compute R^2: training & test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Model 2. PolyLinRegression  #\n",
    "###############################\n",
    "# Re-fit PolyRegression: \n",
    "\n",
    "# Make prediction: PolyReg.\n",
    "\n",
    "# Compute RMSE: training & test set:\n",
    "\n",
    "# Compute R^2: training & test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Model 3. DTRegression  #\n",
    "##########################\n",
    "# Re-fit DTRegression: \n",
    "\n",
    "# RandomizedSearchCV: DTRegressor\n",
    "# Create hyperparameter list:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Make prediction: DTReg.\n",
    "\n",
    "# Compute RMSE: training & test set:\n",
    "\n",
    "# Compute R^2: training & test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Model 4. RFRegression  #\n",
    "##########################\n",
    "# Re-fit RFRegression: \n",
    "\n",
    "# RandomizedSearchCV: RFRegressor\n",
    "# Create hyperparameter list:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Make prediction: RFReg.\n",
    "\n",
    "# Compute RMSE: training & test set:\n",
    "\n",
    "# Compute R^2: training & test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Model 5. XGBRegression #\n",
    "##########################\n",
    "# Re-fit XGBRegression: \n",
    "\n",
    "# RandomizedSearchCV: XGBRegressor\n",
    "# Create hyperparameter list:\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "# Make prediction: XGBReg.\n",
    "\n",
    "# Compute RMSE: training & test set:\n",
    "\n",
    "# Compute R^2: training & test set:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: model evaluation based on performance metrics  ###\n",
    "Using L1 regularized selected features, Each regression model was carefully evaluated using R-squared value and RMSE (root mean squared error) metrics. Here is a summarized result of all five tested regression models.\n",
    "\n",
    "#### 1) Linear Regression: ###\n",
    "* RMSE training: 0.xxx < RMSE test: 0.xxx\n",
    "* R^2 training: 0.xxx, R^2 test: 0.xxx\n",
    "\n",
    "#### 2) Polynomial Regression: ###\n",
    "* RMSE training: 0.xxx < RMSE test: 0.xxx\n",
    "* R^2 training: 0.xxx, R^2 test: 0.xxx\n",
    "\n",
    "#### 3) DecisionTree Regression: ### \n",
    "* RMSE training: 0.xxx < RMSE test: 0.xxx\n",
    "* R^2 training: 0.xxx, R^2 test: 0.xxx\n",
    "\n",
    "#### 4) RandomForest Regression: ###\n",
    "* RMSE training: 0.xxx > RMSE test: 0.xxx\n",
    "* R^2 training: 0.xxx, R^2 test: 0.xxx\n",
    "\n",
    "#### 5) XGBoost Regression: ###\n",
    "* RMSE training: 0.xxx > RMSE test: 0.xxx\n",
    "* R^2 training: 0.xxx, R^2 test: 0.xxx\n",
    "\n",
    "Thus, xxx models were performed relatively well compared to other models. Some models were overfitted (RMSE train << RMSE test) and others were underfitted (i.e., RMSE train >> RMSE test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Assessment: with presence of outliers ###\n",
    "* Plotting: sns.residuals, scipy quantile plot, sns.distribution, sm.influence_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features: 3 predictors\n",
    "\n",
    "# Fit LinReg():\n",
    "\n",
    "# Plot: sns.residuals plot using LinReg model\n",
    "\n",
    "# Plot: quantile plot of residuals using LinReg model\n",
    "\n",
    "# Plot: distribution plot of residuals - 3 predictors with outliers\n",
    "\n",
    "# Plot: leverage plot to identify high leverage points in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: checking presence of outliers  ####\n",
    "Plot 1: seaborn residual plot shows that there were quite number of residuals centralized in middle range of predicted housing price. Thus, it indicates the fact that model is doing poor job in middle range of Boston's housing prices.\n",
    "\n",
    "Plot 2: this probablisitc quantile plot provides a clue that distribution of residuals are quite noraml but not perfect as most of data points are aligned with a straight linear regression fit.\n",
    "\n",
    "Plot 3: this residual histogram does confirm that the distribution is quite normal with presence of some outliers on the upper end of tails.\n",
    "\n",
    "Plot 4: identify high leverage and some influence = index 240 and low leverage and high influence data points = indexes 245, 264 and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and print rows with low and high leverage with influences:\n",
    "# High leverage, some influence: 240\n",
    "# Low leverage, high influence: 154,176,242,243,244,245,246,248\n",
    "df[df.index.isin([154,176,240,242,243,244,245,246,248])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "The model was constructed using three features f1, f2 and f3. There are presence of outliers due to somewhat outstanding value occurred in these 'x' number of features.\n",
    "\n",
    "Here are some examples of interpreted outliers:\n",
    "* 154, 176: higher average of 'feature 1' and 'feature 2' thus higher 'y'.\n",
    "* 240: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Assessment: without outliers ###\n",
    "* Plotting: sns.residuals, scipy quantile plot, sns.distribution, sm.influence_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Outliers ##\n",
    " #df.drop(df.index[[]])\n",
    "\n",
    "# Data Partition: cleansed dataframe with outliers removal\n",
    "\n",
    "# Statsmodel ols: post outliers removal\n",
    "\n",
    "# Define input features: 3 predictors - post outliers removal\n",
    "\n",
    "# Re-fit: LinearRegression\n",
    "\n",
    "# Plot: sns.residuals plot [post outliers removal]\n",
    "\n",
    "# Plot: quantile plot of residuals [post outliers removal]\n",
    "\n",
    "# Plot: distribution plot of residuals - 3 predictors with NO outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: post outliers removal ####\n",
    "Plot 1: seaborn residual plot shows that.\n",
    "\n",
    "Plot 2: this probablisitc quantile plot provides a clue that distribution of residuals \n",
    "\n",
    "Plot 3: this residual histogram does confirm that the distribution "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
